{
  "repoUrl": "https://github.com/Rishika-Mashetty/universal-content-extractor/",
  "owner": "Rishika-Mashetty",
  "repo": "universal-content-extractor",
  "description": null,
  "stars": 0,
  "forks": 0,
  "summary": "Here's a summary of the `Rishika-Mashetty/universal-content-extractor` repository:\n\n1️⃣ **Short summary**\nThis repository provides a collection of Node.js scripts for extracting, transcribing, and summarizing content from popular social media platforms like Instagram, LinkedIn, X (Twitter), and YouTube. It combines headless browser automation (Puppeteer) for robust data retrieval with Google's Gemini API for advanced AI capabilities, including video transcription and intelligent text summarization.\n\n2️⃣ **Detailed breakdown**\n*   **Multi-Platform Content Extraction:** Offers dedicated modules to scrape public posts/videos from Instagram, LinkedIn, X (Twitter), and YouTube, ensuring broad content coverage.\n*   **Headless Browser Automation:** Utilizes Puppeteer extensively to navigate web pages, handle dynamic content loading, and extract data by mimicking user interaction, bypassing direct API limitations.\n*   **AI-Powered Summarization:** Integrates with the Google Gemini API (using different models like `gemini-2.0-flash`, `gemini-2.5-flash`, `gemini-2.5-pro`) to generate concise, engaging summaries of the extracted textual content.\n*   **Multimedia Transcription:** For video content on Instagram and YouTube, the project can download the media, then leverage the Gemini API to transcribe spoken words, making video content summarizable.\n*   **Robust Data Retrieval:** Includes logic for extracting metadata (title, description), captions/subtitles (YouTube), author information, hashtags, and the main textual content from posts.\n*   **Modular & Script-Based Architecture:** Each platform's extraction logic is encapsulated within its own TypeScript file, making the codebase organized and easier to maintain.\n*   **Environmental Configuration:** Employs `dotenv` to securely manage API keys (e.g., Gemini) and other sensitive configurations.\n*   **Local File Handling:** Can download videos/audio and save comprehensive summaries or transcripts to local files.\n\n3️⃣ **Key files/modules and their roles**\n*   `src/instagram.ts`: Extracts post data (caption, author, hashtags) and video metadata, downloads the video, transcribes its audio via Gemini, and summarizes the full content.\n*   `src/linkedin.ts`: Scrapes author, title, description, and hashtags from LinkedIn posts, then summarizes the text using Gemini.\n*   `src/x.ts`: Extracts the complete text content from X (Twitter) tweets, including long-form \"Notes,\" using Puppeteer. (Note: Currently lacks Gemini summarization).\n*   `src/youtube.ts`: Fetches video title, description, attempts to retrieve official captions, or downloads audio for transcription and comprehensive summarization by Gemini, saving the output.\n*   `package.json`: Manages project dependencies (`puppeteer`, `axios`, `@google/generative-ai`, `dotenv`, `xml2js`, `youtube-dl-exec`) and scripts.\n*   `tsconfig.json`: TypeScript compiler configuration, indicating the project's use of TypeScript.\n\n4️⃣ **Probable tech stack and architecture**\n*   **Primary Language:** TypeScript / JavaScript (Node.js)\n*   **Web Scraping/Automation:** Puppeteer (orchestrates headless Chromium/Chrome).\n*   **HTTP Client:** Axios for network requests.\n*   **AI/Generative Models:** Google Gemini API (via `@google/generative-ai` SDK) for text summarization and audio/video transcription.\n*   **Multimedia Utilities:** `youtube-dl-exec` for YouTube media downloads; `xml2js` for parsing XML-based captions.\n*   **Configuration Management:** `dotenv` for environment variables.\n*   **Architecture:** A collection of independent Node.js scripts, each targeting a specific social media platform. The architecture is primarily sequential: scrape data -> process/download media -> apply AI -> output results. It's designed for individual content processing rather than a scalable, real-time service.\n\n5️⃣ **Risks or missing aspects**\n*   **Fragile Scraping:** Relying on Puppeteer for web scraping is susceptible to UI changes on target platforms, requiring frequent maintenance to update selectors and extraction logic.\n*   **Scalability & Performance:** The current approach of launching a new headless browser instance for each operation is resource-intensive and slow, hindering scalability for high-volume content processing.\n*   **Rate Limiting & IP Blocking:** Without advanced proxy management or more sophisticated delay/retry logic, aggressive scraping could lead to IP bans or rate limits from social media platforms.\n*   **Incomplete AI Integration for X:** The `src/x.ts` module currently only extracts text and lacks the Gemini API integration for summarization found in other modules, making its \"universal\" aspect incomplete.\n*   **Limited Error Handling:** While some basic error handling is present, more robust mechanisms for network failures, API errors, or unexpected page structures would improve reliability.\n*   **No Authentication Support:** The project focuses on publicly accessible content and lacks support for authenticated sessions, limiting its use cases for private or protected content.\n*   **Missing Documentation:** The absence of a `README.md` makes setup and usage instructions unclear for new users, including required `.env` variables and command execution.\n*   **Gemini API Constraints:** Transcription and summarization via Gemini API are subject to rate limits, costs, and content size/duration limitations, which might affect processing of very long videos.\n*   **Inconsistent Output Structure:** The final output format and data points vary slightly between platform modules, which could complicate integration into a unified system."
}